{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import cluster\n",
    "from sklearn import feature_extraction\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BOSTON_DATA = \"Food_Establishment_Inspections_(converted).csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHICAGO_DATA = \"Food_Inspections_(converted).csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load boston data\n",
    "boston_df = pandas.read_csv(BOSTON_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load chicago data\n",
    "chicago_df = pandas.read_csv(CHICAGO_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take a random sample of 100k records\n",
    "boston_df2 = boston_df.sample(100000)\n",
    "\n",
    "# map 'Fail' to 0 and other (generally 'Pass') to 1\n",
    "boston_result = boston_df2['result'].map(lambda x: 0 if x == \"Fail\" else 1)\n",
    "\n",
    "# get a subset of fields for machine learning, make sure none of the field values are 'NaN'\n",
    "boston_subset = boston_df2[[\"businessName\", \"violation\", \"risk\", \"city\"]]\n",
    "boston_subset = boston_subset.replace(pandas.np.nan,' ', regex=True)\n",
    "\n",
    "# convert the dataframe into an array of dictionarys and generate feature matrix\n",
    "boston_dict = boston_subset.to_dict('records')\n",
    "boston_fm = vec.fit_transform(boston_dict).toarray()\n",
    "\n",
    "# load back into a dataframe\n",
    "df2 = pandas.DataFrame(boston_fm)\n",
    "\n",
    "# split data into training and test datasets\n",
    "boston_fm_train, boston_fm_test, target_train, target_test = train_test_split(df2, boston_result, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boston_model = DecisionTreeClassifier()\n",
    "\n",
    "# generate decision tree from boston training dataset\n",
    "%time boston_model.fit(boston_fm_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "train_predicted = boston_model.predict(boston_fm_train)\n",
    "print(metrics.classification_report(target_train, train_predicted))\n",
    "print(metrics.confusion_matrix(target_train, train_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate model evaluation metrics\n",
    "test_predicted = boston_model.predict(boston_fm_test)\n",
    "print(metrics.classification_report(target_test, test_predicted))\n",
    "print(metrics.confusion_matrix(target_test, test_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert violation values to string\n",
    "chicago_df['violation'] = chicago_df['violation'].astype('str')\n",
    "\n",
    "# take a random sample of 100k records\n",
    "chicago_df2 = chicago_df.sample(100000)\n",
    "\n",
    "# map 'Fail' to 0 and other (generally 'Pass') to 1\n",
    "chicago_result = chicago_df2['result'].map(lambda x: 0 if x == \"Fail\" else 1)\n",
    "\n",
    "# get a subset of fields for machine learning, make sure none of the field values are 'NaN'\n",
    "chicago_subset = chicago_df2[[\"businessName\", \"violation\", \"risk\", \"city\"]]\n",
    "chicago_subset = chicago_subset.replace(pandas.np.nan,' ', regex=True)\n",
    "\n",
    "# convert the dataframe into an array of dictionarys and generate feature matrix\n",
    "chicago_dict = chicago_subset.to_dict('records')\n",
    "chicago_fm = vec.fit_transform(chicago_dict).toarray()\n",
    "\n",
    "# load back into a dataframe\n",
    "chicago_df3 = pandas.DataFrame(chicago_fm)\n",
    "\n",
    "# split data into training and test datasets\n",
    "chicago_fm_train, chicago_fm_test, chicago_target_train, chicago_target_test = train_test_split(chicago_df3, chicago_result, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chicago_model = DecisionTreeClassifier()\n",
    "\n",
    "# generate decision tree from chicago training dataset\n",
    "%time chicago_model.fit(chicago_fm_train, chicago_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "chi_train_predicted = chicago_model.predict(chicago_fm_train)\n",
    "print(metrics.classification_report(chicago_target_train, chi_train_predicted))\n",
    "print(metrics.confusion_matrix(chicago_target_train, chi_train_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate model evaluation metrics\n",
    "chi_test_predicted = chicago_model.predict(chicago_fm_test)\n",
    "print(metrics.classification_report(chicago_target_test, chi_test_predicted))\n",
    "print(metrics.confusion_matrix(chicago_target_test, chi_test_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chicago_df['violation'] = chicago_df['violation'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_df = boston_df + chicago_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take a random sample of 100k records\n",
    "combined_df2 = combined_df.sample(50000)\n",
    "\n",
    "# map 'Fail' to 0 and other (generally 'Pass') to 1\n",
    "combined_result = combined_df2['result'].map(lambda x: 0 if x == \"Fail\" else 1)\n",
    "\n",
    "# get a subset of fields for machine learning, make sure none of the field values are 'NaN'\n",
    "combined_subset = combined_df2[[\"businessName\", \"violation\", \"risk\", \"city\"]]\n",
    "combined_subset = combined_subset.replace(pandas.np.nan,' ', regex=True)\n",
    "\n",
    "# convert the dataframe into an array of dictionarys and generate feature matrix\n",
    "combined_dict = combined_subset.to_dict('records')\n",
    "combined_fm = vec.fit_transform(combined_dict).toarray()\n",
    "\n",
    "# split data into training and test datasets\n",
    "combined_fm_train, combined_fm_test, combined_target_train, combined_target_test = train_test_split(combined_fm, combined_result, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.38 s, sys: 10.9 s, total: 16.2 s\n",
      "Wall time: 20.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model = DecisionTreeClassifier()\n",
    "\n",
    "# generate decision tree from chicago training dataset\n",
    "%time combined_model.fit(combined_fm_train, combined_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00     40000\n",
      "\n",
      "avg / total       1.00      1.00      1.00     40000\n",
      "\n",
      "[[40000]]\n"
     ]
    }
   ],
   "source": [
    "combined_train_predicted = combined_model.predict(combined_fm_train)\n",
    "print(metrics.classification_report(combined_target_train, combined_train_predicted))\n",
    "print(metrics.confusion_matrix(combined_target_train, combined_train_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00     10000\n",
      "\n",
      "avg / total       1.00      1.00      1.00     10000\n",
      "\n",
      "[[10000]]\n"
     ]
    }
   ],
   "source": [
    "# generate model evaluation metrics\n",
    "combined_test_predicted = combined_model.predict(combined_fm_test)\n",
    "print(metrics.classification_report(combined_target_test, combined_test_predicted))\n",
    "print(metrics.confusion_matrix(combined_target_test, combined_test_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
